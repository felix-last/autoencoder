{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import intracluster_smote\n",
    "import evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mnist_utils\n",
    "import asirra_utils\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import sklearn.model_selection\n",
    "import traceback\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import keras\n",
    "import autoencoder_keras\n",
    "from keras.callbacks import TensorBoard\n",
    "# Fixup for keras for Tensorboard > 0.12\n",
    "import tensorflow as tf\n",
    "tf.merge_all_summaries = tf.summary.merge_all\n",
    "tf.train.SummaryWriter = tf.summary.FileWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Credit Card Dataset\n",
    "# https://www.kaggle.com/dalpozz/creditcardfraud\n",
    "cc_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "def load_cc(ratio=None):\n",
    "    cc_data_raw = pd.read_csv('datasets/creditcard.csv')\n",
    "    cc_data_target = cc_data_raw['Class']\n",
    "    cc_data = cc_data_raw.drop(['Class'], axis=1)\n",
    "    cc_data = cc_scaler.fit_transform(cc_data)\n",
    "    return np.asarray(cc_data), np.asarray(cc_data_target)\n",
    "cc_data_full = load_cc()\n",
    "train_id,test_id = next(sklearn.model_selection.StratifiedShuffleSplit(test_size=0.5, n_splits=1).split(cc_data_full[0],cc_data_full[1]))\n",
    "cc_data_train = cc_data_full[0][train_id]\n",
    "cc_data_train_target = cc_data_full[1][train_id]\n",
    "cc_data_test = cc_data_full[0][test_id]\n",
    "cc_data_test_target = cc_data_full[1][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try different architectures of ae for reconstruction error with training_set/validation_set\n",
    "# try different #layers\n",
    "# try different #units\n",
    "# verify: does linear transformation (i.e. PCA) affect the performance of the neural network?\n",
    "# check reconstruction quality on an individual sample level - how well does it actually reconstruct individual points?\n",
    "# different optimizers\n",
    "# initialization of weights: Xavier Initialization (normal distr. with SD depending on # of input units)\n",
    "# activation functions: try tanh, relu\n",
    "# architecture of network for this dataset kaggle\n",
    "# try not reducing (i.e. compressing) at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'layers': [30,20,15,20,30],\n",
    "    'optimizer': 'adadelta',\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'regularize': False,\n",
    "    'batch_size':256,\n",
    "    'epoch_count':5000,\n",
    "    'name':'default 30-20-15',\n",
    "}\n",
    "grid = [default_params,\n",
    " ###### LAYER STRUCTURE ########\n",
    "{\n",
    "    'layers': [30,15,15,10,15,15,30],\n",
    "    'name':'L 30-15-15-10',\n",
    "},{\n",
    "    'layers': [30,15,30],\n",
    "    'name':'L 30-15',\n",
    "},{\n",
    "    'layers': [30,15,10,15,30],\n",
    "    'name':'L 30-15-10',\n",
    "},{\n",
    "    'layers': [30,30,30],\n",
    "    'name':'L 30-30',\n",
    "},###### OPTIMIZERS ########\n",
    "{\n",
    "    'optimizer': keras.optimizers.SGD(lr=0.01, momentum=0.7, decay=0.0, nesterov=True),\n",
    "    'name':'O SGD Nesterov 0.7',\n",
    "},{\n",
    "    'optimizer': 'adagrad',\n",
    "    'name':'O Adagrad',\n",
    "},{\n",
    "    'optimizer': 'adagrad',\n",
    "    'name':'O Nadam',\n",
    "},##### BATCH SIZE #####\n",
    "{\n",
    "    'batch_size':1000,\n",
    "    'name':'B 1,000',\n",
    "},{\n",
    "    'batch_size':10000,\n",
    "    'name':'B 10,000',\n",
    "},#### REGULIZATION #####\n",
    "# {\n",
    "#     'regularize':True,\n",
    "#     'name':'Regularized',\n",
    "# },##### COMBINATION ######\n",
    "{\n",
    "    'optimizer': 'adagrad',\n",
    "    'batch_size':1000,\n",
    "    'layers': [30,20,10,20,30],\n",
    "    'epoch_count':1500,\n",
    "    'name':'O Adagrad; B 1,000; L 30-20-10',\n",
    "},{\n",
    "    'optimizer': 'adagrad',\n",
    "    'batch_size':1000,\n",
    "    'layers': [30,15,10,15,30],\n",
    "    'epoch_count':1500,\n",
    "    'name':'O Adagrad; B 1,000; L 30-15-10',\n",
    "},{\n",
    "    'optimizer': 'adagrad',\n",
    "    'batch_size':1000,\n",
    "    'layers': [30,10,30],\n",
    "    'epoch_count':1500,\n",
    "    'name':'O Adagrad; B 1,000; L 30-10',\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'adagrad', 'batch_size': 1000, 'epoch_count': 1500, 'loss': 'binary_crossentropy', 'name': 'O Adagrad; B 1,000; L 30-15-10', 'layers': [30, 10, 30], 'regularize': False}\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    }
   ],
   "source": [
    "for i, configuration in enumerate(grid):\n",
    "    if i < 12: continue\n",
    "    params = {**default_params, **configuration}\n",
    "    print('\\n',params)\n",
    "    folder = 'results/cc_optimization_1500/{0} {1}'.format(i, params['name'])\n",
    "    ae = autoencoder_keras.Autoencoder(\n",
    "        layers=params['layers'],\n",
    "        regularize=params['regularize'],\n",
    "        optimizer=params['optimizer'],\n",
    "        loss=params['loss'],\n",
    "        training_set=cc_data_train\n",
    "    )\n",
    "    ae.fit(cc_data_train, cc_data_train,\n",
    "            nb_epoch=params['epoch_count'],\n",
    "            batch_size=params['batch_size'],\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "            callbacks=[TensorBoard(log_dir=(folder))],\n",
    "            validation_data=(cc_data_test,cc_data_test)\n",
    "    )\n",
    "    try:\n",
    "        np.save(folder+'/ae_weights', ae.get_parameters())\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a22644a4cd7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ae = autoencoder_keras.Autoencoder(\n\u001b[1;32m      4\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mregularize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'regularize'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i=11\n",
    "params = {**default_params, **grid[i]}\n",
    "ae = autoencoder_keras.Autoencoder(\n",
    "        layers=params['layers'],\n",
    "        regularize=params['regularize'],\n",
    "        optimizer=params['optimizer'],\n",
    "        loss=params['loss'],\n",
    "        training_set=cc_data_train\n",
    "    )\n",
    "folder = 'results/cc_optimization_5000/{0} {1}'.format(i, params['name'])\n",
    "ae.set_parameters(np.load(folder+'/ae_weights.npy'))\n",
    "print(folder+'/ae_weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ff = ae.decode(ae.encode(cc_data_test))\n",
    "diff = cc_data_test - ff\n",
    "diff_at_target = diff[np.asarray(cc_data_test_target, dtype='bool')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(diff.reshape((diff.size))).describe())\n",
    "sns.heatmap(diff[np.random.choice(diff.shape[0], size=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(diff_at_target.reshape((diff_at_target.size))).describe())\n",
    "sns.heatmap(diff_at_target[np.random.choice(diff_at_target.shape[0], size=30)])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
